4 library ( openNLPmodels . en )
5 library ( tm )
6 library ( stringr )
7 library ( gsubfn )
8 library ( plyr )
library ( NLP )
3 library ( openNLP )
4 library ( openNLPmodels . en )
5 library ( tm )
6 library ( stringr )
7 library ( gsubfn )
8 library ( plyr )
exit()
getwd()
benchmarks <- function(y, h) {
require(forecast)
# Compute four benchmark methods
fcasts <- rbind(
N = snaive(y, h)$mean,
E = forecast(ets(y), h)$mean,
A = forecast(auto.arima(y), h)$mean,
T = thetaf(y, h)$mean)
colnames(fcasts) <- seq(h)
method_names <- rownames(fcasts)
# Compute all possible combinations
method_choice <- rep(list(0:1), length(method_names))
names(method_choice) <- method_names
combinations <- expand.grid(method_choice) %>% tail(-1) %>% as.matrix()
# Construct names for all combinations
for (i in seq(NROW(combinations))) {
rownames(combinations)[i] <- paste0(method_names[which(combinations[i, ] > 0)],
collapse = "")
}
# Compute combination weights
combinations <- sweep(combinations, 1, rowSums(combinations), FUN = "/")
# Compute combinations of forecasts
return(combinations %*% fcasts)
}
errors <- map(M3, function(u) {
train <- u$x
test <- u$xx
f <- benchmarks(train, u$h)
error <- -sweep(f, 2, test)
pcerror <- (200 * abs(error) / sweep(abs(f), 2, abs(test), FUN = "+")) %>%
as_tibble() %>%
mutate(Method = rownames(f)) %>%
gather(key = h, value = sAPE, -Method)
scalederror <- (abs(error) / mean(abs(diff(train, lag = frequency(train))))) %>%
as_tibble() %>%
mutate(Method = rownames(f)) %>%
gather(key = h, value = ASE, -Method)
return(list(pcerror = pcerror, scalederror = scalederror))
})
library(Mcomp)
library(tidyverse)
install.packages("Mcomp")
library(Mcomp)
library(tidyverse)
errors <- map(M3, function(u) {
train <- u$x
test <- u$xx
f <- benchmarks(train, u$h)
error <- -sweep(f, 2, test)
pcerror <- (200 * abs(error) / sweep(abs(f), 2, abs(test), FUN = "+")) %>%
as_tibble() %>%
mutate(Method = rownames(f)) %>%
gather(key = h, value = sAPE, -Method)
scalederror <- (abs(error) / mean(abs(diff(train, lag = frequency(train))))) %>%
as_tibble() %>%
mutate(Method = rownames(f)) %>%
gather(key = h, value = ASE, -Method)
return(list(pcerror = pcerror, scalederror = scalederror))
})
errors
M3errors <- tibble(
Series = names(M3),
Period = map_chr(M3, "period"),
se = map(errors, "scalederror"),
pce = map(errors, "pcerror")) %>%
unnest() %>%
select(-h1, -Method1) %>%
mutate(h = as.integer(h),
Period = factor(str_to_title(Period),
levels = c("Monthly","Quarterly","Yearly","Other")))
M3errors
accuracy <- M3errors %>%
group_by(Period, Method, h) %>%
summarize(MASE=mean(ASE), sMAPE=mean(sAPE)) %>%
ungroup()
original_methods <- unique(accuracy[["Method"]])
original_methods <- original_methods[str_length(original_methods)==1L]
# Compute summary table of accuracy measures
accuracy_table <- accuracy %>%
group_by(Method,Period) %>%
summarise(
sMAPE = mean(sMAPE, na.rm = TRUE),
MASE = mean(MASE, na.rm = TRUE) ) %>%
arrange(MASE) %>% ungroup()
best <- accuracy_table %>% filter(MASE==min(MASE))
accuracy_table <- accuracy_table %>%
filter(Method %in% original_methods | Method %in% best$Method) %>%
arrange(Period, MASE) %>%
select(Period, Method, sMAPE, MASE)
knitr::kable(accuracy_table)
order <- accuracy_table %>% group_by(Method) %>%
summarise(MASE = mean(MASE)) %>% arrange(MASE) %>%
pull("Method") %>% rev()
accuracy %>%
gather(key = "Measure", value = "accuracy", sMAPE, MASE) %>%
filter(Method %in% unique(accuracy_table$Method)) %>%
mutate(Method = factor(Method, levels=order)) %>%
ggplot(aes(x = h, y = accuracy), group = Method) +
geom_line(aes(col = Method)) +
facet_grid(rows = vars(Measure), cols=vars(Period), scale = "free") +
xlab("Forecast horizon") + ylab("Forecast accuracy")
eat_ensemble <- function(y, h = ifelse(frequency(y) > 1, 2*frequency(y), 10)) {
require(forecast)
fets <- forecast(ets(y), h)
farima <- forecast(auto.arima(y), h)
ftheta <- thetaf(y, h)
comb <- fets
comb$mean <-(fets$mean + farima$mean + ftheta$mean)/3
comb$method <- "ETS-ARIMA-Theta Combination"
return(comb)
}
USAccDeaths %>% eat_ensemble() %>% autoplot()
M3
M3
data("iris")
library(keras)
library(dplyr)
library(ggplot2)
library(purrr)
imdb <- dataset_imdb(num_words = 10000)
c(train_data, train_labels) %<-% imdb$train
c(test_data, test_labels) %<-% imdb$test
word_index <- dataset_imdb_word_index()
word_index_df <- data.frame(
word = names(word_index),
idx = unlist(word_index, use.names = FALSE),
stringsAsFactors = FALSE
)
# The first indices are reserved
word_index_df <- word_index_df %>% mutate(idx = idx + 3)
word_index_df <- word_index_df %>%
add_row(word = "<PAD>", idx = 0)%>%
add_row(word = "<START>", idx = 1)%>%
add_row(word = "<UNK>", idx = 2)%>%
add_row(word = "<UNUSED>", idx = 3)
word_index_df <- word_index_df %>% arrange(idx)
decode_review <- function(text){
paste(map(text, function(number) word_index_df %>%
filter(idx == number) %>%
select(word) %>%
pull()),
collapse = " ")
}
train_data <- pad_sequences(
train_data,
value = word_index_df %>% filter(word == "<PAD>") %>% select(idx) %>% pull(),
padding = "post",
maxlen = 256
)
test_data <- pad_sequences(
test_data,
value = word_index_df %>% filter(word == "<PAD>") %>% select(idx) %>% pull(),
padding = "post",
maxlen = 256
)
# input shape is the vocabulary count used for the movie reviews (10,000 words)
vocab_size <- 10000
model <- keras_model_sequential()
model %>%
layer_embedding(input_dim = vocab_size, output_dim = 50) %>%
layer_global_average_pooling_1d() %>%
layer_dense(units = 50, activation = "relu") %>%
#layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
model %>% summary()
model %>% compile(
optimizer = 'adam',
loss = 'binary_crossentropy',
metrics = list('accuracy')
)
plot(model %>% fit(
partial_x_train,
partial_y_train,
epochs = 500,
batch_size = 512,
validation_data = list(x_val, y_val), validation_split = 0.4, #callbacks = callbacks,
verbose=1
))
plot(model %>% fit(
partial_x_train,
partial_y_train,
epochs = 500,
batch_size = 512,
validation_split = 0.4, #callbacks = callbacks, validation_data = list(x_val, y_val)
verbose=1
))
plot(model %>% fit(
train_data,
train_labels,
epochs = 500,
batch_size = 512,
validation_split = 0.4, #callbacks = callbacks, validation_data = list(x_val, y_val)
verbose=1
))
library(keras)
library(dplyr)
library(ggplot2)
library(tidyr)
library(tibble)
num_words <- 10000
imdb <- dataset_imdb(num_words = num_words)
c(train_data, train_labels) %<-% imdb$train
c(test_data, test_labels) %<-% imdb$test
multi_hot_sequences <- function(sequences, dimension) {
multi_hot <- matrix(0, nrow = length(sequences), ncol = dimension)
for (i in 1:length(sequences)) {
multi_hot[i, sequences[[i]]] <- 1
}
multi_hot
}
train_data <- multi_hot_sequences(train_data, num_words)
test_data <- multi_hot_sequences(test_data, num_words)
first_text <- data.frame(word = 1:10000, value = train_data[1, ])
ggplot(first_text, aes(x = word, y = value)) +
geom_line() +
theme(axis.title.y = element_blank(),
axis.text.y = element_blank(),
axis.ticks.y = element_blank())
##CREATE A BASELINE MODEL
baseline_model <-
keras_model_sequential() %>%
layer_dense(units = 16, activation = "relu", input_shape = 10000) %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
baseline_model %>% compile(
optimizer = "adam",
loss = "binary_crossentropy",
metrics = list("accuracy")
)
baseline_model %>% summary()
baseline_history <- baseline_model %>% fit(
train_data,
train_labels,
epochs = 20,
batch_size = 512,
validation_data = list(test_data, test_labels),
verbose = 2
)
#####CREATE A SMALLER MODEL
smaller_model <-
keras_model_sequential() %>%
layer_dense(units = 4, activation = "relu", input_shape = 10000) %>%
layer_dense(units = 4, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
smaller_model %>% compile(
optimizer = "adam",
loss = "binary_crossentropy",
metrics = list("accuracy")
)
smaller_model %>% summary()
smaller_history <- smaller_model %>% fit(
train_data,
train_labels,
epochs = 20,
batch_size = 512,
validation_data = list(test_data, test_labels),
verbose = 2
)
### CREATE A BIGGER MODEL
bigger_model <-
keras_model_sequential() %>%
layer_dense(units = 512, activation = "relu", input_shape = 10000) %>%
layer_dense(units = 512, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
bigger_model %>% compile(
optimizer = "adam",
loss = "binary_crossentropy",
metrics = list("accuracy")
)
bigger_model %>% summary()
bigger_history <- bigger_model %>% fit(
train_data,
train_labels,
epochs = 20,
batch_size = 512,
validation_data = list(test_data, test_labels),
verbose = 2
)
##PLOT THE TRAINING AND VALIDATION LOSS
compare_cx <- data.frame(
baseline_train = baseline_history$metrics$loss,
baseline_val = baseline_history$metrics$val_loss,
smaller_train = smaller_history$metrics$loss,
smaller_val = smaller_history$metrics$val_loss,
bigger_train = bigger_history$metrics$loss,
bigger_val = bigger_history$metrics$val_loss
) %>%
rownames_to_column() %>%
mutate(rowname = as.integer(rowname)) %>%
gather(key = "type", value = "value", -rowname)
ggplot(compare_cx, aes(x = rowname, y = value, color = type)) +
geom_line() +
xlab("epoch") +
ylab("loss")
###### ADD WEIGHT REGULARIZATION
l2_model <-
keras_model_sequential() %>%
layer_dense(units = 16, activation = "relu", input_shape = 10000,
kernel_regularizer = regularizer_l2(l = 0.001)) %>%
layer_dense(units = 16, activation = "relu",
kernel_regularizer = regularizer_l2(l = 0.001)) %>%
layer_dense(units = 1, activation = "sigmoid")
l2_model %>% compile(
optimizer = "adam",
loss = "binary_crossentropy",
metrics = list("accuracy")
)
l2_history <- l2_model %>% fit(
train_data,
train_labels,
epochs = 20,
batch_size = 512,
validation_data = list(test_data, test_labels),
verbose = 2
)
## Here’s the impact of our L2 regularization penalty:
compare_cx <- data.frame(
baseline_train = baseline_history$metrics$loss,
baseline_val = baseline_history$metrics$val_loss,
l2_train = l2_history$metrics$loss,
l2_val = l2_history$metrics$val_loss
) %>%
rownames_to_column() %>%
mutate(rowname = as.integer(rowname)) %>%
gather(key = "type", value = "value", -rowname)
ggplot(compare_cx, aes(x = rowname, y = value, color = type)) +
geom_line() +
xlab("epoch") +
ylab("loss")
### ADD DROPOUT
dropout_model <-
keras_model_sequential() %>%
layer_dense(units = 16, activation = "relu", input_shape = 10000) %>%
layer_dropout(0.6) %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dropout(0.6) %>%
layer_dense(units = 1, activation = "sigmoid")
dropout_model %>% compile(
optimizer = "adam",
loss = "binary_crossentropy",
metrics = list("accuracy")
)
dropout_history <- dropout_model %>% fit(
train_data,
train_labels,
epochs = 20,
batch_size = 512,
validation_data = list(test_data, test_labels),
verbose = 2
)
### How well did it work?
compare_cx <- data.frame(
baseline_train = baseline_history$metrics$loss,
baseline_val = baseline_history$metrics$val_loss,
dropout_train = dropout_history$metrics$loss,
dropout_val = dropout_history$metrics$val_loss
) %>%
rownames_to_column() %>%
mutate(rowname = as.integer(rowname)) %>%
gather(key = "type", value = "value", -rowname)
ggplot(compare_cx, aes(x = rowname, y = value, color = type)) +
geom_line() +
xlab("epoch") +
ylab("loss")
ggplot(compare_cx, aes(x = rowname, y = value, color = type)) +
geom_line() +
xlab("epoch") +
ylab("loss")
getwd()
food_rev_df <- read.csv('./FPM003/Hackathon/Food_Review_App/food_fe.csv')
str(food_rev_df)
dim(food_rev_df)
set.seed(1024)
ind <- sample(2, nrow(food_rev_df), replace=TRUE, prob=c(0.85, 0.15))
dt_food_rev <- food_rev_df[ind==1,c(2:33,40)]
dv_food_rev <- food_rev_df[ind==2,c(2:33,40)]
summary(dv_food_rev)
dv_food_rev <- as.data.frame(apply(dv_food_rev, 2, function(x) (x-min(x))/(max(x)-min(x))))
dt_food_rev <- as.data.frame(apply(dt_food_rev, 2, function(x) (x-min(x))/(max(x)-min(x))))
###head(dt_food_rev)
lm_food_rev <- lm(Votes_Value~.,dt_food_rev)
summary(lm_food_rev)
plot(lm_food_rev)
plot(lm_food_rev)
rmse_lm
rmse_lm <- (mean((predict(lm_food_rev,dv_food_rev[ , -33]) - dv_food_rev[ , 33])^2))^1/2 ##0.0005329834378
rmse_lm
##### N NET
library(neuralnet)
nn_food_rev <- neuralnet(Votes_Value ~ is_Located_Outside_India + is_NCR + Counts_of_Restaurants_in_the_city +
Average_Votes_per_Restaurant + Restaurants_in_city...5 +
Restaurants_in_city....25 + Avg..daily.orders + Average_Cost_for_Two +
Has_Table + Has_Online_Orders + Percentage.online.orders +
Desserts + Café.Flag + is_Eco + is_Mid + is_High + Alcohol +
Continental + Oriental + Oceanic + Asian + American + Café.Pub +
Fast.Food + Desserts...Beverages + Latin.American + Arabic +
International + Indian + Mediterranean + Health.Conscious +
European,
data = dt_food_rev)
nn_pred <- compute(nn_food_rev,dv_food_rev[ , -33])
nn_pred <- as.data.frame(nn_pred)
rmse_nn <- (mean((nn_pred$net.result - dv_food_rev[ , 33])^2))^1/2 ### 0.001219104027
rmse_nn
swirl()
require(swirl())
swirl()
swirl()
install.packages("rms")
install.packages("bife")
install.packages("bife")
## SKJ AKA Raja Hummushit
setwd("/Users/IIMS Bloomberg ONE/Downloads/Kaggle_Do_NOT_Delete/FPM003/Hackathon/EA/FaceData/")
df.bjp <- read.csv("bjp.csv")
View(df.bjp)
dim(df.bjp)## 39986    10
### Other than english
length(noneng.match <- grep("\\?", df.bjp$message)) ## 9237
df.bjp.eng <- df.bjp[-noneng.match,]
dim(df.bjp.eng)
View(df.bjp.eng)
sum(is.na(df.bjp.eng)) #### Blank spaces though
textdata.bjp <- df.bjp.eng$message
View(textdata.bjp)
sum(!trimws(textdata.bjp, 'b') == "")
textdata.bjp <- textdata.bjp[!trimws(textdata.bjp, 'b') == ""]
sum(trimws(textdata.bjp, 'b') == "")
textdata.bjp = gsub("[[:punct:]]", "", textdata.bjp)
textdata.bjp = gsub("[[:punct:]]", "", textdata.bjp)
textdata.bjp = gsub("[[:digit:]]", "", textdata.bjp)
textdata.bjp = gsub("http\\w+", "", textdata.bjp)
textdata.bjp = gsub("[ \t]{2,}", "", textdata.bjp)
textdata.bjp = gsub("^\\s+|\\s+$", "", textdata.bjp)
source("classify_emotion.R")
source("create_matrix.R")
source("classify_polarity.R")
try.error = function(x)
{
y = NA
try_error = tryCatch(tolower(x), error=function(e) e)
if (!inherits(try_error, "error"))
y = tolower(x)
return(y)
}
test = sapply(textdata.bjp, try.error)
textdata.bjp <- textdata.bjp[!trimws(textdata.bjp, 'b') == ""]
sum(trimws(textdata.bjp, 'b') == "")
sum(is.na(textdata.bjp))
#### Text mining :: The real one
require(tm)
require(SnowballC)
class_emo = classify_emotion(textdata.bjp, algorithm="bayes", prior=1.0)
emotion = class_emo[,7]
emotion
class_pol = classify_polarity(textdata.bjp, algorithm="bayes")
save.image("bjpCong.RData")
sent_df = data.frame(text=textdata.bjp, emotion=emotion,
polarity=polarity, stringsAsFactors=FALSE)
sent_df = within(sent_df,
emotion <- factor(emotion, levels=names(sort(table(emotion), decreasing=TRUE))))
sent_df = data.frame(text=textdata.bjp, emotion=emotion,
polarity=polarity, stringsAsFactors=FALSE)
polarity = class_pol[,4]
sent_df = data.frame(text=textdata.bjp, emotion=emotion,
polarity=polarity, stringsAsFactors=FALSE)
sent_df = within(sent_df,
emotion <- factor(emotion, levels=names(sort(table(emotion), decreasing=TRUE))))
require(ggplot2)
ggplot(sent_df, aes(x=emotion)) +
geom_bar(aes(y=..count.., fill=emotion)) +
scale_fill_brewer(palette="Dark2") +
labs(x="emotion categories", y="")
ggplot(sent_df, aes(x=polarity)) +
geom_bar(aes(y=..count.., fill=polarity)) +
scale_fill_brewer(palette="RdGy") +
labs(x="polarity categories", y="")
emos = levels(factor(sent_df$emotion))
nemo = length(emos)
emo.docs = rep("", nemo)
for (i in 1:nemo)
{
tmp = textdata.bjp[emotion == emos[i]]
emo.docs[i] = paste(tmp, collapse=" ")
}
emo.docs = removeWords(emo.docs, stopwords("english"))
corpus = Corpus(VectorSource(emo.docs))
tdm = TermDocumentMatrix(corpus)
tdm = as.matrix(tdm)
colnames(tdm) = emos
require(wordcloud)
comparison.cloud(tdm, colors = brewer.pal(nemo, "Dark2"),
scale = c(3,.5), random.order = FALSE,
title.size = 1.5)
plot(tdm, corThreshold = 0.2, weighting = TRUE)
v <- sort(rowSums(tdm),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
wordcloud(d$word,d$freq)
exit
exit()
